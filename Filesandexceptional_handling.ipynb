{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXURJvueR/r/TkywSwd1RN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Debasmita0596/Python-Basics-Assignment/blob/main/Filesandexceptional_handling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
        "Multithreading and multiprocessing are both strategies for parallelism in programming, but each is better suited to certain scenarios depending on the nature of the task. Here’s a breakdown of when each is preferable:\n",
        "\n",
        "When Multithreading is Preferable:\n",
        "Multithreading involves multiple threads within the same process, sharing the same memory space. This approach is generally better for tasks that are I/O-bound or where task switching cost is minimal.\n",
        "\n",
        "I/O-Bound Tasks:\n",
        "\n",
        "Scenario: Applications that spend a lot of time waiting for I/O operations (like reading from disk, waiting for network responses, or user input) are typically ideal for multithreading.\n",
        "Example: Web scraping, network services, or applications that require many I/O operations, such as file servers.\n",
        "Why Multithreading: Threads can efficiently manage and wait for I/O tasks without consuming CPU resources, allowing other threads to proceed without blocking.\n",
        "Shared Memory Requirement:\n",
        "\n",
        "Scenario: Tasks that need to frequently share data (e.g., read/write shared variables) can benefit from multithreading due to lower memory overhead and ease of data sharing.\n",
        "Example: Real-time data processing in GUI applications, like updating user interface elements based on background operations.\n",
        "Why Multithreading: Threads share the same memory space, so data sharing between threads is simpler and faster than using multiprocessing, which requires data to be pickled and passed between separate memory spaces.\n",
        "Low Resource Overhead:\n",
        "\n",
        "Scenario: Applications with many small, lightweight tasks that can execute quickly.\n",
        "Example: Applications with frequent context-switching requirements, such as light background tasks in a web server.\n",
        "Why Multithreading: Threads within a process use less memory and have a lower startup and context-switching cost than separate processes.\n",
        "Concurrency on Single-core Machines:\n",
        "\n",
        "Scenario: When only a single CPU core is available, multithreading can create the illusion of parallelism by rapidly switching between threads.\n",
        "Example: Running a lightweight server on a low-powered device (e.g., IoT device) with minimal CPU power.\n",
        "Why Multithreading: It can improve perceived responsiveness without true parallel execution, especially beneficial when handling I/O-bound tasks.\n",
        "When Multiprocessing is Preferable:\n",
        "Multiprocessing involves multiple processes, each with its own memory space, which can utilize multiple CPU cores. This is generally better for CPU-bound tasks or when memory isolation is required.\n",
        "\n",
        "CPU-Bound Tasks:\n",
        "\n",
        "Scenario: Tasks that require a lot of CPU computation, like mathematical calculations, data transformations, or complex algorithmic processes.\n",
        "Example: Image processing, machine learning training, data analysis, or scientific computations.\n",
        "Why Multiprocessing: Separate processes can run on different CPU cores, leveraging multi-core architecture to process data in parallel, thus speeding up CPU-bound tasks.\n",
        "Independent or Isolated Tasks:\n",
        "\n",
        "Scenario: Applications that require task isolation to avoid interference between tasks or require a high degree of fault tolerance.\n",
        "Example: Running multiple worker processes in a distributed computing framework.\n",
        "Why Multiprocessing: Separate memory spaces mean tasks are isolated, preventing accidental data corruption or interference, which improves stability.\n",
        "Memory Management and Scalability:\n",
        "\n",
        "Scenario: Applications that need to handle large datasets without sharing memory resources directly between tasks.\n",
        "Example: Batch processing systems, like ETL (Extract, Transform, Load) operations on large datasets.\n",
        "Why Multiprocessing: Each process can independently allocate and manage its own memory, which can lead to better memory management and scalability for high-volume data operations.\n",
        "Avoiding Global Interpreter Lock (GIL) in Python:\n",
        "\n",
        "Scenario: Python programs that need to bypass the Global Interpreter Lock (GIL) for true parallel execution, as the GIL can be a bottleneck in multithreaded programs.\n",
        "Example: Python applications performing heavy CPU-bound tasks, like cryptographic calculations or simulations.\n",
        "Why Multiprocessing: Each process runs in its own Python interpreter instance, thus circumventing the GIL and allowing parallel execution on multiple cores.\n",
        "\n",
        "\n",
        "Summary Table:\n",
        "\n",
        "\n",
        "Scenario                         Approach                       \tRationale\n",
        "\n",
        "I/O-bound\n",
        "tasks                        Multithreading                        Allows\n",
        "                                                                   threads\n",
        "                                                                   to manage\n",
        "                                                                    I/O\n",
        "                                                                  without\n",
        "                                                                  blocking\n",
        "                                                                  CPU\n",
        "                                                                  resources\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "High\n",
        "memory\n",
        "sharing\n",
        "needs                      Multithreading                          \n",
        "                                                                Shared\n",
        "                                                                 memory\n",
        "                                                                allows\n",
        "                                                                efficient\n",
        "                                                                data\n",
        "                                                                exchange\n",
        "                                                                between\n",
        "                                                                threads\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Lightweight\n",
        " or\n",
        "rapid\n",
        " task\n",
        "switching                    Multithreading                   Lower\n",
        "                                                            overhead and\n",
        "                                                              quicker\n",
        "                                                             context-switching\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "CPU-bound tasks               Multiprocessing       Utilizes multiple CPU cores  \n",
        "                                                    for true parallelism\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Tasks requiring\n",
        "isolation                     Multiprocessing        Separate memory spaces\n",
        "                                                     improve isolation and fault tolerance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Large dataset handling       Multiprocessing         Independent memory  \n",
        "                                                     allocation improves memory\n",
        "                                                     management\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Bypassing GIL in Python      Multiprocessing         Independent interpreter\n",
        "                                                    instances avoid the GIL limitation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Each method has its strengths depending on whether the workload is primarily I/O-bound or CPU-bound, as well as on resource sharing and memory isolation needs."
      ],
      "metadata": {
        "id": "7RjX3Ma_ft-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "\n",
        "#A process pool is a collection of pre-spawned processes in a pool that can be used to execute multiple tasks concurrently. It allows an application to distribute tasks to multiple worker processes without repeatedly creating and destroying processes, which can be resource-intensive. Process pools are an efficient solution for handling large numbers of tasks, especially when each task can run independently and in parallel.\n",
        "\n",
        "#How Process Pools Work:\n",
        "#Pre-allocated Processes: When a process pool is created, a fixed number of processes are pre-allocated. These processes remain alive throughout the pool’s lifetime, ready to take on tasks as they arrive.\n",
        "#Task Queueing: Tasks are submitted to the process pool, which places them in a queue. Each process in the pool picks up tasks from this queue as it becomes available, executes the task, and returns the result.\n",
        "#Efficient Resource Use: By reusing the same pool of processes, the system avoids the overhead of repeatedly creating and tearing down processes, saving both memory and CPU resources.\n",
        "#Load Balancing: Process pools can distribute tasks evenly among worker processes, maximizing CPU utilization and ensuring a balanced workload.\n",
        "#Advantages of Process Pools:\n",
        "#Reduced Overhead: Spawning a new process is relatively expensive in terms of time and resources. A process pool reduces this cost by maintaining a set number of processes that are reused for multiple tasks.\n",
        "#Simplified Management: Developers can submit tasks without manually managing the lifecycle of individual processes. The pool handles process creation, task distribution, and termination.\n",
        "#Concurrency Control: By setting the pool size, developers control the maximum number of concurrent processes, which helps manage resource consumption and ensures the system doesn’t get overwhelmed.\n",
        "#Automatic Task Distribution: The process pool’s internal queue system automatically distributes tasks across available processes, allowing for load balancing.\n",
        "#Common Use Cases for Process Pools:\n",
        "#Parallel Data Processing: When working with large datasets, a process pool can help distribute data processing tasks (like filtering, aggregation, or transformations) across multiple CPU cores.\n",
        "#Web Server and Microservices: Process pools are used in web servers to handle multiple requests concurrently without spawning a new process for each request.\n",
        "#Batch Processing and ETL Jobs: For extract, transform, load (ETL) operations in data pipelines, process pools allow parallel processing of large volumes of data.\n",
        "\n",
        "#Example in Python:\n",
        "\n",
        "#Python’s multiprocessing module provides a Pool class that allows the creation of process pools. Here’s an example of how to use it:\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Define a function to execute in parallel\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Create a pool with 4 processes\n",
        "with Pool(4) as pool:\n",
        "    # Map the function to a list of inputs\n",
        "    results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "\n",
        "print(results)  # Output: [1, 4, 9, 16, 25]\n",
        "\n",
        "#In this example, the Pool class creates a pool of 4 worker processes. The map method distributes the square function across the processes, automatically balancing the workload and returning results in the order they were submitted. This efficient, parallel execution significantly speeds up the computation compared to sequential execution.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN8kER0U0-ed",
        "outputId": "db54186d-25d5-4106-94e5-e6434289c87a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Explain what multiprocessing is and why it is used in Python programs.\n",
        "\n",
        "#Multiprocessing is a technique used in programming to run multiple processes simultaneously, allowing tasks to be divided across multiple CPU cores. Each process runs independently, with its own memory space, making multiprocessing ideal for CPU-bound tasks that require heavy computation and benefit from parallel execution.\n",
        "\n",
        "#In Python, multiprocessing is used to overcome the limitations of the Global Interpreter Lock (GIL), which can hinder true parallelism in multithreaded Python programs. The GIL allows only one thread to execute Python bytecode at a time, limiting CPU-bound tasks when using threads. By creating multiple processes instead of threads, the multiprocessing module bypasses the GIL, enabling Python programs to fully utilize multi-core CPUs.\n",
        "\n",
        "#Why Multiprocessing is Used in Python Programs:\n",
        "#Parallelism for CPU-bound Tasks:\n",
        "\n",
        "#CPU-bound tasks, such as data processing, machine learning model training, or scientific computations, benefit greatly from true parallel execution.\n",
        "#Multiprocessing allows these tasks to be split across multiple CPU cores, resulting in faster execution times compared to sequential execution.\n",
        "#Bypassing the Global Interpreter Lock (GIL):\n",
        "\n",
        "#The GIL in Python restricts execution to one thread at a time within a single process, which limits parallelism in CPU-bound multithreaded programs.\n",
        "#Multiprocessing avoids the GIL by creating separate processes, each with its own interpreter instance, allowing for true parallel execution.\n",
        "#Task Isolation and Fault Tolerance:\n",
        "\n",
        "#Since each process has its own memory space, they are isolated from each other. This isolation prevents shared memory issues and improves fault tolerance—if one process crashes, it doesn’t affect others.\n",
        "#This is particularly useful in systems that need to handle multiple tasks independently, such as web servers and data pipelines.\n",
        "#Efficient Use of Multi-core CPUs:\n",
        "\n",
        "#Modern CPUs often have multiple cores, each capable of handling a separate process simultaneously.\n",
        "#Multiprocessing in Python allows developers to make efficient use of these cores by distributing tasks across them, which significantly boosts performance for CPU-intensive applications.\n",
        "\n",
        "\n",
        "#Common Use Cases for Multiprocessing in Python:\n",
        "#Scientific and Numerical Computations: Tasks like matrix operations, simulations, and other data-intensive computations.\n",
        "#Data Processing and ETL (Extract, Transform, Load): Large datasets can be processed in parallel, making ETL jobs much faster.\n",
        "#Machine Learning Training: Many machine learning tasks can be parallelized, especially when working with large datasets or training complex models.\n",
        "#Web Scraping: Multiprocessing can speed up web scraping by fetching data from multiple sites or pages simultaneously.\n",
        "\n",
        "#Example of Using Multiprocessing in Python:\n",
        "\n",
        "#Here’s a simple example using Python’s multiprocessing module to perform parallel computation:\n",
        "\n",
        "from multiprocessing import Process, current_process\n",
        "\n",
        "# Define a function that performs a CPU-bound operation\n",
        "def compute_square(number):\n",
        "    result = number * number\n",
        "    print(f\"Process {current_process().name}: {number}^2 = {result}\")\n",
        "\n",
        "# List of numbers to square\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Create a process for each number\n",
        "processes = []\n",
        "for number in numbers:\n",
        "    process = Process(target=compute_square, args=(number,))\n",
        "    processes.append(process)\n",
        "    process.start()\n",
        "\n",
        "# Wait for all processes to complete\n",
        "for process in processes:\n",
        "    process.join()\n",
        "\n",
        "#n this example:\n",
        "\n",
        "#We create a separate process for each compute_square call.\n",
        "#Each process performs the computation independently and can run on a different CPU core, enabling parallel execution.\n",
        "\n",
        "#This results in faster execution than running each computation sequentially, making multiprocessing an effective way to leverage multiple cores in Python programs."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0IDrKNQ3Enc",
        "outputId": "86206ef4-08c1-4a65-d093-df30fb7ae4ce"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process Process-56: 1^2 = 1\n",
            "Process Process-57: 2^2 = 4\n",
            "Process Process-58: 3^2 = 9\n",
            "Process Process-59: 4^2 = 16\n",
            "Process Process-60: 5^2 = 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.\n",
        "#To safely handle shared data (like a list) between multiple threads, we can use a Lock to avoid race conditions. This ensures that only one thread can modify the list at a time.\n",
        "\n",
        "#Here's a Python program using threading where one thread continuously adds numbers to a shared list and another thread continuously removes numbers from the list. We’ll use threading.Lock to prevent simultaneous access to the list.\n",
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "\n",
        "# Lock to avoid race conditions\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function for adding numbers to the list\n",
        "def add_to_list():\n",
        "    for i in range(10):  # Adding 10 numbers\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate delay\n",
        "        number = random.randint(1, 100)\n",
        "\n",
        "        # Acquire the lock before modifying the list\n",
        "        with list_lock:\n",
        "            shared_list.append(number)\n",
        "            print(f\"Added {number} to the list. Current list: {shared_list}\")\n",
        "\n",
        "# Function for removing numbers from the list\n",
        "def remove_from_list():\n",
        "    for i in range(10):  # Removing 10 numbers\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate delay\n",
        "\n",
        "        # Acquire the lock before modifying the list\n",
        "        with list_lock:\n",
        "            if shared_list:\n",
        "                removed_number = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_number} from the list. Current list: {shared_list}\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "\n",
        "# Creating threads for adding and removing\n",
        "adder_thread = threading.Thread(target=add_to_list)\n",
        "remover_thread = threading.Thread(target=remove_from_list)\n",
        "\n",
        "# Starting the threads\n",
        "adder_thread.start()\n",
        "remover_thread.start()\n",
        "\n",
        "# Waiting for both threads to complete\n",
        "adder_thread.join()\n",
        "remover_thread.join()\n",
        "\n",
        "print(\"Final list:\", shared_list)\n",
        "\n",
        "\n",
        "#Explanation:\n",
        "#Shared Resource: The shared_list is the list both threads are accessing.\n",
        "#Lock Mechanism: A Lock object (list_lock) is used to ensure that only one thread can modify shared_list at a time.\n",
        "\n",
        "\n",
        "\n",
        "#Adding and Removing Functions:\n",
        "#add_to_list: Adds a random number to the list with a simulated delay. It locks the list using with list_lock: to ensure only this thread can access the list during the addition.\n",
        "#remove_from_list: Removes the first item from the list if it's not empty. It also uses with list_lock: to avoid simultaneous access.\n",
        "#Threading and Synchronization: Both adder_thread and remover_thread start simultaneously but are synchronized through the Lock to prevent race conditions.\n",
        "\n",
        "\n",
        "#Output:\n",
        "#The output will vary due to randomness in the time delay and numbers generated, but the locking mechanism ensures that:\n",
        "\n",
        "#Only one thread modifies the list at any time.\n",
        "#No race conditions occur, maintaining consistent list operations.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4t49K6x6pp9",
        "outputId": "cbc949a1-814d-4e54-a018-67376aea1b27"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 81 to the list. Current list: [81]\n",
            "Removed 81 from the list. Current list: []\n",
            "List is empty, nothing to remove.\n",
            "List is empty, nothing to remove.\n",
            "Added 67 to the list. Current list: [67]\n",
            "Added 28 to the list. Current list: [67, 28]\n",
            "Removed 67 from the list. Current list: [28]\n",
            "Added 96 to the list. Current list: [28, 96]\n",
            "Removed 28 from the list. Current list: [96]\n",
            "Added 27 to the list. Current list: [96, 27]\n",
            "Removed 96 from the list. Current list: [27]\n",
            "Removed 27 from the list. Current list: []\n",
            "Added 52 to the list. Current list: [52]\n",
            "Removed 52 from the list. Current list: []\n",
            "Added 65 to the list. Current list: [65]\n",
            "Removed 65 from the list. Current list: []\n",
            "Added 14 to the list. Current list: [14]\n",
            "Added 5 to the list. Current list: [14, 5]\n",
            "Removed 14 from the list. Current list: [5]\n",
            "Added 70 to the list. Current list: [5, 70]\n",
            "Final list: [5, 70]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
        "#In Python, sharing data safely between threads and processes is essential to avoid race conditions, ensure data consistency, and maintain program stability. Here’s a summary of the primary methods and tools available in Python for managing data sharing in both multithreaded and multiprocessed contexts.\n",
        "#1. For Threads: Using threading Module\n",
        "#Since threads in Python share the same memory space, they can access and modify the same objects directly. However, this can lead to race conditions, so thread synchronization tools are necessary:\n",
        "\n",
        "#threading.Lock:\n",
        "\n",
        "#A simple locking mechanism that allows only one thread to access a resource at a time. Threads acquire the lock before accessing shared data and release it after.\n",
        "import threading\n",
        "\n",
        "counter = 0\n",
        "lock = threading.Lock()\n",
        "\n",
        "def increment():\n",
        "    global counter\n",
        "    with lock:\n",
        "        counter += 1\n",
        "\n",
        "#threading.RLock (Reentrant Lock):\n",
        "\n",
        "#Similar to Lock, but allows a thread to acquire the same lock multiple times. Useful in cases where code might call a function that locks itself, preventing a deadlock.\n",
        "rlock = threading.RLock()\n",
        "#threading.Semaphore:\n",
        "\n",
        "#Used to control access to a resource, allowing a specified number of threads to access it simultaneously.\n",
        "semaphore = threading.Semaphore(2)  # Allows two threads at a time\n",
        "#threading.Event:\n",
        "\n",
        "#A signaling mechanism that lets threads wait for certain conditions. Useful for coordinating threads without sharing specific data.\n",
        "#threading.Condition:\n",
        "\n",
        "#Allows threads to wait until notified, often used with a lock to enable threads to wait for some state before proceeding.\n",
        "\n",
        "#2. For Processes: Using multiprocessing Module\n",
        "#Processes in Python have separate memory spaces, so sharing data directly between them requires different tools, primarily provided by the multiprocessing module:\n",
        "\n",
        "#multiprocessing.Queue:\n",
        "\n",
        "#A thread- and process-safe FIFO queue that can be used to share data between processes.\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "q = Queue()\n",
        "\n",
        "def worker(queue):\n",
        "    queue.put(\"data\")\n",
        "\n",
        "p = Process(target=worker, args=(q,))\n",
        "p.start()\n",
        "p.join()\n",
        "print(q.get())  # Retrieves data from the queue\n",
        "#multiprocessing.Manager:\n",
        "\n",
        "#Provides a shared memory manager that can create data structures accessible across processes, like list, dict, Namespace, and more.\n",
        "from multiprocessing import Process, Manager\n",
        "\n",
        "with Manager() as manager:\n",
        "    shared_list = manager.list()\n",
        "\n",
        "    def append_item(shared_list):\n",
        "        shared_list.append(\"item\")\n",
        "\n",
        "    p = Process(target=append_item, args=(shared_list,))\n",
        "    p.start()\n",
        "    p.join()\n",
        "    print(shared_list)\n",
        "#multiprocessing.Value and multiprocessing.Array:\n",
        "\n",
        "#For sharing simple data types and arrays across processes in shared memory.\n",
        "\n",
        "from multiprocessing import Value, Process\n",
        "\n",
        "counter = Value(\"i\", 0)  # 'i' for integer\n",
        "\n",
        "def increment(counter):\n",
        "    with counter.get_lock():\n",
        "        counter.value += 1\n",
        "\n",
        "p = Process(target=increment, args=(counter,))\n",
        "p.start()\n",
        "p.join()\n",
        "print(counter.value)\n",
        "\n",
        "#multiprocessing.Pipe:\n",
        "\n",
        "#Enables direct communication between two processes through a two-way connection. Useful for bidirectional communication between processes.\n",
        "\n",
        "from multiprocessing import Pipe, Process\n",
        "\n",
        "def worker(pipe):\n",
        "    pipe.send(\"message\")\n",
        "\n",
        "parent_conn, child_conn = Pipe()\n",
        "p = Process(target=worker, args=(child_conn,))\n",
        "p.start()\n",
        "print(parent_conn.recv())\n",
        "p.join()\n",
        "\n",
        "#3. Shared Memory with multiprocessing.shared_memory (Python 3.8+)\n",
        "#Shared memory allows data to be shared between processes without serialization, which can be faster and more efficient for large datasets.\n",
        "\n",
        "#shared_memory Module:\n",
        "#Enables creation of shared memory blocks that can be accessed by different processes, suitable for sharing large arrays of data like NumPy arrays.\n",
        "from multiprocessing import shared_memory\n",
        "import numpy as np\n",
        "\n",
        "# Create shared memory block\n",
        "shm = shared_memory.SharedMemory(create=True, size=1024)\n",
        "\n",
        "# Access shared memory as a NumPy array\n",
        "array = np.ndarray((256,), dtype=np.int32, buffer=shm.buf)\n",
        "\n",
        "\n",
        "\n",
        "#Summary Table\n",
        "\n",
        "#Method/Tool\t                             Threads or Processes                                                 \tUse Case\n",
        "#threading.Lock\t                                Threads\t                            Avoid race conditions when accessing shared resources\n",
        "#threading.RLock\t                               Threads\t                               Reentrant access for nested locking\n",
        "#threading.Condition\t                           Threads\t                      Coordinating threads based on specific conditions\n",
        "#queue.Queue\t                             Threads or Processes\t                     FIFO data sharing, thread-safe and process-safe queues\n",
        "#threading.Event\t                               Threads\t                           Simple signaling between threads\n",
        "#multiprocessing.Value & Array               \tProcesses\t                            Sharing primitive data types or arrays between processes\n",
        "#multiprocessing.Manager\t                    Processes\t                           Sharing complex data structures like lists and dictionaries between processes\n",
        "#multiprocessing.Pipe\t                        Processes                    \tBidirectional communication between two processes\n",
        "#multiprocessing.shared_memory\t              Processes\t                              Directly share large data structures (e.g., numpy arrays) without data copying\n",
        "\n",
        "#These tools allow Python developers to manage concurrent data access safely and efficiently, whether in threads or across multiple processes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6orG7YL8d5M",
        "outputId": "e0aacb46-871f-4ab0-d6ef-f173fa1bbde7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n",
            "['item']\n",
            "1\n",
            "message\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
        "\n",
        "#Handling exceptions in concurrent programs is crucial for several reasons. When dealing with multiple threads or processes, exceptions can lead to unexpected behavior, data corruption, or even crashes if not managed properly. Here’s why exception handling is vital in concurrent programming, along with techniques to effectively manage exceptions.\n",
        "\n",
        "#Why Exception Handling is Crucial\n",
        "#Data Integrity:\n",
        "\n",
        "#Unhandled exceptions can leave shared resources in an inconsistent state, leading to data corruption. For example, if a thread fails while updating a shared variable, the data may become partially updated, causing issues for other threads that rely on it.\n",
        "#Program Stability:\n",
        "\n",
        "#Concurrent programs are typically more complex and prone to errors. An unhandled exception in one thread or process may cause the entire application to terminate unexpectedly, disrupting user experience or critical operations.\n",
        "#Resource Management:\n",
        "\n",
        "#Exceptions can lead to resource leaks, such as open file handles or network connections. Properly handling exceptions allows for the cleanup of resources, ensuring that they are released back to the system, which is particularly important in long-running applications.\n",
        "#Debugging and Logging:\n",
        "\n",
        "#Exception handling provides a mechanism to log errors and relevant context, making it easier to identify and troubleshoot issues in concurrent environments. Without proper logging, diagnosing problems can become very challenging.\n",
        "#User Feedback:\n",
        "\n",
        "#In applications with user interfaces, unhandled exceptions may result in a poor user experience. Properly handling exceptions allows developers to provide meaningful feedback to users, improving usability and satisfaction.\n",
        "#Techniques for Handling Exceptions in Concurrent Programs\n",
        "#Try-Except Blocks:\n",
        "\n",
        "#Use try-except blocks within the thread or process functions to catch exceptions locally. This allows you to handle errors specific to that thread or process without affecting others.\n",
        "import threading\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        # Code that may raise an exception\n",
        "        result = 10 / 0  # Example exception\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Error in {threading.current_thread().name}: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "#Thread or Process-Specific Exception Handling:\n",
        "\n",
        "#Each thread can have its own error handling logic, which can be tailored to its specific needs. This way, an error in one thread doesn’t propagate to others.\n",
        "#Using Futures with ThreadPoolExecutor and ProcessPoolExecutor:\n",
        "\n",
        "#When using the concurrent.futures module, exceptions raised in worker threads or processes can be captured and re-raised when calling result() on the Future object. This allows the main thread to handle exceptions in a centralized manner.\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def worker(x):\n",
        "    if x == 0:\n",
        "        raise ValueError(\"Zero is not allowed!\")\n",
        "    return 10 / x\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "    futures = [executor.submit(worker, i) for i in range(3)]\n",
        "    for future in futures:\n",
        "        try:\n",
        "            result = future.result()  # This will raise the ValueError if it occurred in the thread\n",
        "            print(result)\n",
        "        except ValueError as e:\n",
        "            print(f\"Caught an exception: {e}\")\n",
        "\n",
        "#Custom Exception Classes:\n",
        "\n",
        "#Define custom exceptions to differentiate between different error conditions in your concurrent program. This can help in identifying specific issues and applying appropriate handling strategies.\n",
        "\n",
        "class CustomError(Exception):\n",
        "    pass\n",
        "\n",
        "#Signal Handling (for Processes):\n",
        "\n",
        "#In multiprocessing applications, use signal handling to manage unexpected terminations or to gracefully shut down processes. This can include capturing signals such as SIGTERM or SIGINT to handle shutdown cleanly.\n",
        "#Using finally Blocks:\n",
        "\n",
        "#Always include cleanup code in a finally block to ensure that necessary cleanup (like closing files or releasing resources) happens regardless of whether an exception occurred\n",
        "\n",
        "try:\n",
        "    file = open(\"data.txt\", \"r\")\n",
        "    content = file.read()\n",
        "    print(content)\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found.\")\n",
        "finally:\n",
        "    #file.close()\n",
        "    print(\"File closed.\")\n",
        "\n",
        "#Centralized Exception Handling:\n",
        "\n",
        "#Implement centralized logging or error handling mechanisms. For example, using a global exception handler for logging uncaught exceptions can provide insights into errors across the application.\n",
        "#Summary\n",
        "#In summary, effectively handling exceptions in concurrent programs is essential for maintaining data integrity, stability, and user experience. By employing techniques such as try-except blocks, using futures for centralized error handling, and implementing cleanup mechanisms, developers can create robust concurrent applications that gracefully handle errors and maintain consistent behavior. Proper exception handling not only improves the reliability of the application but also simplifies debugging and enhances overall application quality."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMD9oJyVEwQ7",
        "outputId": "5d234a9c-811f-47bb-93a6-7a3c43d7665f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in Thread-41 (worker): division by zero\n",
            "Caught an exception: Zero is not allowed!\n",
            "10.0\n",
            "5.0\n",
            "File not found.\n",
            "File closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "#Here's a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently. Each factorial calculation runs in a separate thread managed by a thread pool.\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial of a given number\n",
        "def calculate_factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main function to run the program\n",
        "def main():\n",
        "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
        "\n",
        "    # Create a thread pool with 5 workers\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        # Submit tasks to the executor for each number\n",
        "        futures = {executor.submit(calculate_factorial, num): num for num in numbers}\n",
        "\n",
        "        # Retrieve and print results as they complete\n",
        "        for future in futures:\n",
        "            number = futures[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "                print(f\"Factorial of {number} is {result}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating factorial of {number}: {e}\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "#Explanation\n",
        "#Function Definition (calculate_factorial):\n",
        "\n",
        "#This function calculates the factorial of a number and prints a message when starting the calculation.\n",
        "#Thread Pool with ThreadPoolExecutor:\n",
        "\n",
        "#A ThreadPoolExecutor is created with a maximum of 5 threads (max_workers=5).\n",
        "#For each number in the range 1 to 10, a task is submitted to the executor to calculate the factorial, and a Future object is created to manage each task.\n",
        "#Handling Results:\n",
        "\n",
        "#After submitting all tasks, the program iterates over the Future objects, retrieves the result for each completed task, and prints the factorial result.If an exception occurs in any thread, it’s caught and printed.\n",
        "#Sample Output\n",
        "#The actual output will vary slightly depending on thread execution timing, but it will look similar to this:\n",
        "'''Calculating factorial of 1\n",
        "Calculating factorial of 2\n",
        "Calculating factorial of 3\n",
        "Calculating factorial of 4\n",
        "Calculating factorial of 5\n",
        "Factorial of 1 is 1\n",
        "Calculating factorial of 6\n",
        "Factorial of 2 is 2\n",
        "Factorial of 3 is 6\n",
        "Calculating factorial of 7\n",
        "Factorial of 4 is 24\n",
        "Calculating factorial of 8\n",
        "Factorial of 5 is 120\n",
        "Factorial of 6 is 720\n",
        "Calculating factorial of 9\n",
        "Factorial of 7 is 5040\n",
        "Factorial of 8 is 40320\n",
        "Calculating factorial of 10\n",
        "Factorial of 9 is 362880\n",
        "Factorial of 10 is 3628800'''\n",
        "#Using a thread pool allows us to run several factorial calculations concurrently, improving performance by handling multiple tasks simultaneously."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "YhsLNNyLjALr",
        "outputId": "6855ea39-b2c2-44e1-e890-b8e67029d9b3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating factorial of 1\n",
            "Calculating factorial of 2\n",
            "Calculating factorial of 3\n",
            "Calculating factorial of 4\n",
            "Calculating factorial of 5\n",
            "Calculating factorial of 6\n",
            "Calculating factorial of 7Calculating factorial of 8\n",
            "Calculating factorial of 9\n",
            "Calculating factorial of 10\n",
            "\n",
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Calculating factorial of 1\\nCalculating factorial of 2\\nCalculating factorial of 3\\nCalculating factorial of 4\\nCalculating factorial of 5\\nFactorial of 1 is 1\\nCalculating factorial of 6\\nFactorial of 2 is 2\\nFactorial of 3 is 6\\nCalculating factorial of 7\\nFactorial of 4 is 24\\nCalculating factorial of 8\\nFactorial of 5 is 120\\nFactorial of 6 is 720\\nCalculating factorial of 9\\nFactorial of 7 is 5040\\nFactorial of 8 is 40320\\nCalculating factorial of 10\\nFactorial of 9 is 362880\\nFactorial of 10 is 3628800'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "#processes).\n",
        "#Here’s a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program measures the time taken for different pool sizes (2, 4, and 8 processes) to help demonstrate the effect of parallelism on execution time.\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "# Main function to run the program\n",
        "def main():\n",
        "    numbers = list(range(1, 11))  # Numbers from 1 to 10\n",
        "    pool_sizes = [2, 4, 8]  # Different pool sizes to test\n",
        "\n",
        "    for pool_size in pool_sizes:\n",
        "        # Measure the start time\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Create a Pool with the current pool size\n",
        "        with multiprocessing.Pool(processes=pool_size) as pool:\n",
        "            # Map the compute_square function to each number in the list\n",
        "            results = pool.map(compute_square, numbers)\n",
        "\n",
        "        # Measure the end time and calculate elapsed time\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        # Print the results and time taken\n",
        "        print(f\"\\nPool size: {pool_size}\")\n",
        "        print(f\"Squares: {results}\")\n",
        "        print(f\"Time taken: {elapsed_time:.4f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "#Explanation\n",
        "#compute_square Function:\n",
        "\n",
        "#This function takes a single integer n and returns its square.\n",
        "#Pool Size Experimentation:\n",
        "\n",
        "#The pool_sizes list specifies the different sizes of the process pool to test (2, 4, and 8 processes).\n",
        "#For each pool size, the program:\n",
        "#Measures the start time using time.time().\n",
        "#Creates a multiprocessing.Pool with the specified number of processes.\n",
        "#Uses pool.map() to apply compute_square to each number in the numbers list.\n",
        "#Measures the end time and calculates the elapsed time for the computation.\n",
        "#Output:\n",
        "\n",
        "#For each pool size, the program outputs the computed squares and the time taken to perform the computation.\n",
        "\n",
        "#Sample Output\n",
        "#The actual times may vary depending on the system, but the output structure will look like this:\n",
        "\n",
        "'''Pool size: 2\n",
        "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
        "Time taken: 0.1234 seconds\n",
        "\n",
        "Pool size: 4\n",
        "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
        "Time taken: 0.0987 seconds\n",
        "\n",
        "Pool size: 8\n",
        "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
        "Time taken: 0.0876 seconds'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "3Whc2E4hkPzK",
        "outputId": "9eb67f0a-44e0-4754-dc4d-068fcc23235d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pool size: 2\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0292 seconds\n",
            "\n",
            "Pool size: 4\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0550 seconds\n",
            "\n",
            "Pool size: 8\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.1022 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pool size: 2\\nSquares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\\nTime taken: 0.1234 seconds\\n\\nPool size: 4\\nSquares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\\nTime taken: 0.0987 seconds\\n\\nPool size: 8\\nSquares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\\nTime taken: 0.0876 seconds'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}